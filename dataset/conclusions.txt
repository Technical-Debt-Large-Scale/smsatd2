We have proposed a model-driven approach for managing ATD’s life cycle during the software architecture design pro- cess at architecture level only. This is based on the exhaustive heterogeneous architect review process used to locate ATD injection motivators and its impact. NLP techniques and Alloy Analyser are used to find ATD. The viewing of ATD items allows architects to be conscious of any ATD associated with decisions and gives way to strategies that eventually lead to solutions. In this research we faced several challenges that became evident in the case study. First, much of the software architec- ture decisions were not fully documented. Client does not pay for documentation. Rationale of decisions is divided among several artifacts. In this case study we found that Slack was used to justify some decisions. Also, we found that several diagrams were made using PowerPoint. Another challenge we faced was the recovery process of these sources. One of the authors is part of the project so it was easy to have access to this information, but other projects couldn’t have its information so accessible. Also, more complex projects will require more artifacts to analyze and this will include different storing structures. Future work will include convolutional neural networks to train a model to understand diagrams made in PowerPoint or another tool and saved as an image, such as IMEAV [19]. We also plan to include a recommendation system to suggests repayment strategies under certain conditions. Different meta- models for storing ATD should be reviewed. Finally, we will also look into including automatic text extraction methods for audio/video recordings to reduce human interaction.Companies need to develop systems that are sustainable for long term. To do so, they need to monitor and timely repay Architectural Technical Debt, whenever it becomes evident that a substantial interest needs to be paid on such debt. Refactoring deci- sions about the modularization of the system are difficult to take, especially for non-technical stakeholders: refactoring the architecture, to achieve modularity, is an expensive operation, and there- fore the benefits of such decisions need to be clear and quantified. The current status of the art and practice lacks a holistic framework for the identification and estimation of the benefits of repaying ATD, especially to support the stakeholders in quantify- ing the business value of modularization. In this paper, we pro- vide a holistic, semi-automated framework, composed of a Measurement System and an estimation formula, that helps the identification of ATD, reducing the possible candidates for refactoring, and support a cost-effective estimation of the ATD interest. Such results were thoroughly evaluated in a particularly convenient set- ting, where we could conduct a comparative case study, involv- ing existing refactored and non-refactored systems. We propose a novel technique to identify and estimate ATD, and, as such, we make a first step toward providing support to quantify the convenience of repaying ATD in a systematic way. This study provides researchers and practitioners with a reproducible study and practical knowledge to develop a similar framework for further evaluation and for its adaptation to other industrial contexts. The case also provides an initially, quantified evidence (even though related to the single case analyzed) suggesting that refactoring to achieve modularity might pay off in terms of development and maintenance effort, even though such return on investment seems to be achievable in a long-term perspective.In this paper a new index oriented to the evaluation of architectural issues as AS has been proposed and integrated in the Arcan tool. Severity for all the architectural smells detected by Arcan are given and explained. An evaluation of the index has been performed on a dataset of 109 open source projects. The evolution of the ADI and a comparison with the SonarQube TDI index has been performed on 10 projects considering more than 100 versions in total. In the following, we provide the answers to our research questions. With respect to RQ1 How should a new index be formulated to more exhaustively evaluate the architectural debt? Accord- ing to our proposal, the index should take in consideration the architectural smells of the project and their development his- tory. Hence the defined index is computed through the values of ASIS (Architectural Smell Impact Score) and History. The first element estimates the criticality of the AS in terms of the negative impact that they could have on the project. The second element measures the variation of the number of AS in a project during the development history, as explained in Section IV-B. This index can be used to identify and prioritize the most critical classes or packages in the projects; in this way the developers/maintainers can easily identify and focus their attention on them. Moreover, the index can be used to monitor and check the architectural debt during a project evolution. We assessed that our index reflects the architectural debt of the projects by comparing an evaluation done on Eclipse [25] and the value of ADI, both stating the poor architectural quality of the project. With respect to RQ2 How can we estimate the severity of an Architectural Smell? It is possible to estimate the severity for each architectural smell. We considered both SeverityScore and PageRank indexes, described in Section IV-A. The severity evaluation could be also used to estimate the cost- solving of architectural smells. The PageRank has been identified in Section IV-A as a smell-agnostic way to weight the severity of an AS, since it indicates the most important and popular place in the dependency graph (i.e., the elements of the dependency graph that are the hardest to refactor). With agnostic, we mean that the P R uses the dependency graph and it is independent from the AS type. With respect to RQ3 Is the new index based on architectural smell detection independent from another existing index based on code level issues? The indexes seem not to have correlation and inter-dependence according to the three tests we conducted in Section V. Moreover, there is no correlation of ADI with both LOC and Bugs used for the computation of the TDI of SonarQube. TDI showed different trends with respect to ADI highlighting its weakness on architectural quality evaluation, since TDI cannot evaluate any aspect of the architecture of a project which is computed by ADI. In fact we observed that ADI got worst and TDI was stable or getting better in the majority of the projects. This highlights the independence between issues at code level (detected by TDI) and at archi- tectural level (detected by ADI), making our index a valid support for developers to assess architectural quality. According to future developments, we aim to evaluate the index on a large dataset of both open source and industrial projects to get the feedback of the developers [30]. Hence, the weights assigned for example to the History could be changed according to new validations. We focused our effort on the detection of the AS described in Section III, obviously in the future other AS can be considered in the index and detected by Arcan. For example we could consider AS related to Interface design and evolution, such as the AS Ambiguous Interface, Redundant Interface, Overused Interface and Unstable Inter- face [10]. We would like also to detect different categories of AS which could impact different quality attributes, such as performance and security; in this direction, we could identify and compute different ADI index profiles according to the impact of the AS on specific quality attributes. Moreover, we aim to extend the index or define a new one to consider also the cost to remove the architectural smells ( cost- solving). This could allow developers/maintainers to make a business case (costs vs benefits) and help them to set the order in which they want to remove the AS. Towards the definition of this index oriented to the evaluation of the cost-solving, we are also interested to work on the development of some kind of automatic/semiautomatic refactoring support by studying the different refactoring opportunities of each AS. The index now is focused only on the evaluation of the architectural debt derived by AS. Other factors could be considered, e.g. FOSS/COTS obsolescence, legacy monolithic applications and lack of information architecture hardening.In this paper, we present a case study to identify and quantify the effect of architecture debt on software evolution. Through our analyses, we find that: 1) files involved in architecture roots are flawed by architecture issues and are much more change-prone than the other files; 2) during the evolution of software, files involved in architecture roots are associated with higher maintenance effort and this effort is much greater than that of the median file’s changes. In future work, we plan to study the process of issue removal to determine which issues are the most costly to remove and generally extend this analysis to a wider range of project domains and sizes.Our current study covers a period of two years and reports on the process and major findings from identifying and paying down the architecture debt in the module structure of Bright- Squid’s platform. In this study we have observed substantial quality and productivity improvements made over the period of intervention and analysis. Understanding the architecture flaws and initiating refactoring helped the company to reduce their build time by about 83%, reduced the average time to resolve issues by 72%, and reduce bug-fixing effort from an average of 102 LOC per bug to just 34. How do we know that these improvements all accrued to the architecture debt repayment? Again, we can not claim causality based on a single case study. However, we believe that we can make an argument based on a preponderance of evidence all pointing in the same direction. The number and size of the architecture flaws went down, productivity measures went up, the key stakeholders felt that the refactoring benefited their ability to manage the code baseIn this paper, we proposed a model called active hotspots that can be used to monitor software evolution and detect potential degradation, using issues as first-class entities. An active hotspot is formed by seed files that are changed by multiple issues, and the files that are connected with them through one of the 4 propagation patterns. Using active hotspots as lenses, we studied the evolution history of 21 open source projects. The data revealed that within any evolution period, the majority of files revised for issue fixing are just aggregated into a few dominating hotspots, and most of these dominating hotspots are persistent and remain active for a long time, implying that these dominating hotspots should be the focal points of activity and deserve special attention. Different from most code, design, or architecture smell detection tools, the number of files within hotpots do not increase with the size of the project, meaning that developersIn this paper, we provided evidence that the modularity metrics IPCI and IPGF have significant negative correlations with ANMCC – an ATD indicator. Therefore, we can consider the IPCI and IPGF metrics as alternative indicators of ATD. The advantage of using the modularity metrics IPCI and IPGF as ATD indicators is that these modularity metrics can be automatically calculated based on source code (i.e., the update-to-date and accurate structure data of a software system), while ANMCC should be calculated based on commit records that are not always available, and ANMCC calculation is hard to be performed automatically. Moreover, the modularity metric IPCI is more strongly correlated with ANMCC than IPGF, which means that IPCI is a more accurate substitute ATD indicator to ANMCC than IPGF. Based on the results and findings of this work, we plan to do further research in the following directions. First, we intend to validate the correlation between modularity metrics and ANMCC with Java projects. Second, it will be interesting to define new system-wide modularity metrics or adapt existing modularity metrics defined in other perspectives (e.g., complex networks [14]), and investigate the correlation between the metrics and ATD indicators. We expect that the new modularity metrics can improve the accuracy or take less effort of predicting ANMCC. Third, it is practically valuable to develop plugins to calculate the modularity metrics IPCI and IPGF for IDE tools (e.g., in VS2012 or Eclipse).Refactoring Architectural Technical Debt is a task that, for the architects and for large software organization, is risky, difficult to estimate and difficult to be prioritized since the lack of a clear business value for the management [20]. In practice, usually the refactoring is postponed until it is too late and repaying the principal becomes too expensive with respect to paying the interest. As a consequence, the refactoring might not be conducted at all, which leads to slow down the development and brings development crises in which there is no delivered value [3]. In order to tackle this problem, we have empirically developed and evaluated a method, AnaConDebt, with the continuous contribution of several architects in 6 organizations and continuously evaluated it in practice by analyzing 12 concrete cases of ATD. As far as we know, this is the only study in which a method for ATD management has been developed in collaboration with this much industrial input. The aim of study was to provide a tool for taking decisions on if and when ATD should be refactor (RQ1). We have shown how the method can be used for such purpose, and how it was found useful by the architects. The method provides indicators that would estimate the important factors responsible for the growth of interest (RQ2) and therefore would warn the organization (including non-technical stakeholders) that the refactoring is urgent. As an example of the impact on non-technical stakeholders, a product manager participating in one of the session commented: “I entered in this room with an idea, but I’m leaving with a completely new perspectiveTo quantify and manage architectural TD, we formally defined the concept of architectural debt, and then described an approach to automatically identify such debts, to measure their maintenance consequences, and to model their growth. We proposed a novel history model—the HCP matrix—to approximate the probabilities of change propagation among files, and defined 4 patterns based on the HCP matrix to capture problematic architectural connections among files. We evaluated our approach on 7 large-scale Apache open source projects and the results showed that a significant portion (51% to 85%) of overall maintenance effort was consumed by paying interest on architectural debts. This suggests that projects could save a significant amount of maintenance costs if they can discover these debts early, and pay them down by refactoring. The top 5 architectural debts in each of the 7 projects consume a non-trivial portion (20% to 61%) of each project’s maintenance effort, but they only contain a small portion of each project’s error-prone files (8% to 25%). Thus investing in refactoring small groups of files could reap large benefits. Finally, we quantified the growing trend of maintenance costs for each debt. About half of the debts grow linearly, meaning that developers pay a consistently increasing penalty on these debts in every release. And using DSMs, we qualitatively illustrated how architectural issues connect more files, incur more maintenance costs, and evolve into debts over time.In this research we present a novel approach to identify ATD of Android apps based on architectural guidelines extraction and modeling, architecture reverse engineering, and compliance checking. We plan to fully automate the process and extensively evaluate it on large set of Android apps. The approach enables us to conduct evolutionary studies on the ATD of Android apps, through which a higher precision of the approach could be achieved, e.g. by considering code churn to rank more precisely ATDIs.Not availableStrategic decisions on the prioritization of costly ATD are critical for software companies. To prioritize the refactoring of ATD, companies need to be aware of what interest is being paid and what interest is going to be paid in the future. The current body of knowledge lacks a solid conceptual representation of the interest on the basis of empirical studies, and the community lacks applicable approaches to estimate the interest and to prioritize ATD: as a result, the architects' decisions are based on individual experience and intuitive judgment, and the repayment of ATD is consequently hard to justify for the management. Estimating the extra costs associated with the interest requires knowledge about what phenomena and extra activities are generated by the ATD. In this study, we have collected a broad amount of cases where large software companies experienced on the payment of large amount of interest. We have categorized the ATD in classes and mapped them to costly interest represented by sociotechnical phe- nomena occurring during software development and extra activities generating costs. The paper reports patterns of sociotechnical events that lead to a novel phenomenon, call contagious debt; this is based on vicious cycles of events that cause ATD to propagate in the system and generate a continuous increment of interest. We report evidence that this phenomenon is a potential trigger for the accumulation of compound interest, the source of fast‐growing hidden costs, which might become nonlinear over time. This paper can be considered the first study in reporting a large amount of empirical evidence on the occurrence of compound interest and of the sociotechnical patterns leading to it. Our results provide clear targets for which new informa- tion and, consequently, a new combination of measures are needed to estimate the interest and the compound interest of ATD. Such results can be valuable in making practitioners aware of what kind of interest they might have to pay if the ATD is not repaid. Finally, we provide a list of the factors that cause the debt to propagate throughout the sys- tem, becoming contagious. These factors can be proactively monitored to strategically refactor the ATD, before it becomes too costly to be repaid. Our recent work, involving methods and tools for the estima- tion of the interest on the basis of the factors outlined here, reported several benefits of using such information during software development. P.S. The taxonomy of ATD items might not be complete, because we focused on the most expensive violations mentioned by the practitioners. Also, different contexts might show different effects for the recognized items, in which case the taxonomy might result as different.In this paper, we described our experience in using three tools able to provide a quality/debt index, with the aim of evaluating the architectural debt and the overall quality of a software project. We found that Sonargraph provides the largest set of useful functions for the considered task. We think that this experience report can be useful to de- velopers or maintainers to have a summary on the state of tools in identifying architectural debt, and to tools’ devel- opers to improve their tools. For example, we found that the available Indexes summarizing the quality or debt of the projects are not directly useful when evaluating a sin- gle project. These measures cannot be interpreted with the aim to understand the overall quality of the analyzed project on a global scale. In other words, the number cannot tell if the project is good or not. Of consequence, we think that these Indexes are currently useful only on a relative scale, in the case a single team evaluates an entire portfolio of applications. In future experiments, we aim to similarly consider other tools, e.g., the commercial tool CAST, tools that provide dependency analysis and other tools developed in academia, e.g., Hotspot Detector, TamDera. Moreover, we are interested in inspecting other dimensions of archi- tectural debt, as the history of projects, and in analyzing large-scale industrial systems.We propose an approach to identify ATD based on architecture decisions and change scenarios. This approach provides the capability to identify ATD types that existing ATD identification approaches, mainly based on source code analysis, cannot identify. The results of the industrial case study show that the proposed approach is effective in identifying ATD. Specifically, the approach is useful in identifying real ATD, the granularity of the change scenarios used for ATD identification is appropriate for ATD interest measurement, and the identified ATD items are helpful to release planning. The case study results also show that the approach is easy to use. Our approach shows a high potential in identifying ATD that makes it visible to stakeholders. We plan to replicate the case study in more industrial projects with different sizes and from various domains. We also plan to customize the approach in order to make it suitable for an agile context, with appropriate tool support.Decisions on short term and long term prioritization of architecture improvements need to be balanced and need to rely on the knowledge of the underlying phenomenon of ATD. The reaching of a crisis point when the ATD is hindering the responsiveness in providing new customer value, as required in ASD, has shown to be a relevant problem that many companies struggle with. Such crisis point seems to be inevitable given the continuous accumulation of ATD and the impossibility to recover all of it. However, the act of slowing down the ATD accumulation would reduce, in the long term, the number of crisis points when a huge costly refactoring or the replacement of the whole system need to be conducted. We have shown such accumulation and recovery trends over time in order to inform RQ1. We have shown what are the causes of the accumulation of ATD, and we outline, through the recognition of different influencing factors, clear objectives that can be treated or further studied in order to avoid or mitigate the accumulation of ATD, which informs RQ2. An important goal in research and industry is to improve the practices to uncover ATD present in the system. It’s also important to identify the best points in time for performing refactoring and therefore repaying the debt that is going to generate more interest effort later on. Such practices need to complement the current Agile process in place, in order to keep responsiveness stable through the whole software development process.Refactoring decisions about the modularization of the system are difficult to take, especially for non-technical stakeholders. Refactoring the architecture to achieve modularity is an expensive operation, and therefore the benefits of such decisions need to be clear and therefore quantified. The current status of the art and practice is lacking an estimation method to support the stakeholders in quantifying the business value of modularization. In this paper, we provide a method to select the part of a component on which the interest of Architectural Technical Debt is paid, by defining the Files Of Interests, and using such information together with project data in an estimation equation (Equation 2) to calculate and quantify the benefits of refactoring in man-hours. Such results make a first step in providing support to quantify the benefits of refactoring and provides researchers and practitioners with a repeatable method. The case also provides an initial quantified evidence that refactoring to achieve modularity pays off in terms of development and maintenance effort, even though in a long-term perspective.In this paper, we performed a case study within a large software company, to understand how practitioners identify and prioritize Architectural Technical Debt using automatically detected architectural smells. Four industrial projects have been analyzed, and a sample of the detected AS has been thoroughly inspected by the projects’ practitioners to find the causes of the issues, and to assess their negative impact and refactoring costs based on their perception and experience. We found which AS pointed at the most harmful Architectural Technical Debt (RQ1), which ones have more impact (RQ2.1), which ones cost more to refactor (RQ2.2) and which ones are, overall, more convenient to detect and prioritize (RQ2). From the combined results, we can conclude that using AS to identify and prioritize ATD was considered useful: the tool helped identifying half of the problems that were not previously known by the practitioners, and provided evidence for the known ones. However, some AS were not considered high pri- ority, which helps researchers to further improve and filter the automatically revealed AS. Cyclic Dependency was the AS with the worst impact but also the most expensive to refactor, while Hub Like Dependency has also a similar strong negative impact but seems to be the most convenient to detect and to refactor (less costly). On the contrary, Unstable Dependency was not perceived as an issue. In the future, we plan to perform new case studies in other industrial domains and companies. We aim to better explore the refactoring cost of the smells to improve the prioritization of the smells to be removed first. According to this aspect we would like to ask practitioners to evaluate the usefulness of a new Architectural Debt Index [25], which allows to identify and assess the overall architectural debt of a project by taking into account the severity of each archi- tectural smell. The index can be used to evaluate the most critical parts and to monitor the evolution of the architectural debt during the project history. Finally, we aim to analyze and detect through Arcan other categories of architectural smells other than those related to dependency issues, such as smells related to the interface (Ambiguous Interface, Redundant Interface and Unstable Interface [26]) or smells related to performance or security issues.In our earlier work we argued that the software industry needs to adopt ideas and principles from “Manufacturing Execution Systems” into software development practices ([14], [15]). In this work we claimed that an MES-style approach, with integrated, continuously-collected data about process activities can aid in planning and estimation accuracy, process improvement, and product quality. The DRSpace approach provides one piece of this vision—a means by which a project manager or architect can continuously monitor product quality, comparing it to project, organization, or industry norms. And, using the continuously collected information, a manager can make reasoned, economics-based decisions on if and when to refactor. This allows the project to manage and control a form of technical debt: architectural debt. We liken this process to that of a health monitor, that continuously measures a patient’s vital signs, providing timely and critical feedback to health-care professionals. Such feedback is essential to determine whether to stage an intervention and to assess the success of any such intervention. Interventions, in the form of refactorings, are the principle means by which an architecture’s health can be improved. A DRSpace - based analysis not only can aid in determining whether such a refactoring is required, but can aid in assessing the return-on- investment of such an intervention. In this way project stakeholders can make such decisions in confidence, based on hard empirical data. In this paper we reviewed the three main ways, based on our Titan tool chain that we monitor and manage architecture debt: by tracking the architecture roots, by tracking architecture flaws, and by tracking DL. These techniques have now been applied on over 150 projects, including 30 large-scale industrial projects, and have provided valuable insight to project stakeholders.Our case study with SoftServe has confirmed our research hypotheses: we are able to locate the architectural sources of technical debt, quantify them, and quantify the expected pay- back for refactoring these debts. We did this based solely on data that was already available within SoftServe. The evidence that we produced and the arguments that we made based on this evidence were compelling to SoftServe’s management, who immediately decided to invest in the proposed refac- torings. One might object that these estimates are just that– estimates. However, all decision-making in business involves investment under uncertainty. And even if our ROI estimate is off by an order of magnitude—that is, if it was merely a 30% ROI—it still represents an excellent choice for the company, which presumably can not earn such a high ROI through any traditional means. Our future work consists of a longitudinal study wherein we do four things: First, we will track the architectural integrity of this system on a regular basis. That is, we plan to analyze periodic snapshots of SoftServe’s system, to see whether the refactoring is being done correctly, and whether it is eroding over time. Second, we plan to continue to track the frequency of reported defects, and their connection to the files in SS1. Third we plan to continue to track the frequency of changes to the files of SS1. Finally, we plan to track the lines of code committed to fix defects and to make changes. This longitudinal data capture and analysis will allow us to validate the expectations and opinions collected in the present study, and to build better predictive models for SoftServe in the future. We are also in the process of conducting other industrial case studies, to show the repeatability of our methods in different industrial contexts. In addition, we would like to examine the background trends of the data in future work. For example, are bug rates, change rates, and churn level, going up, or going down in the project, irrespective of any intervention? For now, SoftServe is very happy with the outcomes and is taking all necessary steps to refactor their architecture to fix the defects that our Titan tool has highlighted. The SoftServe architects felt that Titan provided insights, supporting data and, (most important) explanations that no other analysis tool had hitherto provided. These insights accorded with their experience of the system, and supported their intuitions about the problems with its architecture. But, more importantly, the combination of project-data-driven economic arguments and evidence-based identification of technical debts was com- pelling for SoftServe’s architects and they plan to pursue this strategy with other systems right away.The prioritization of ATD with respect to feature development, a critical issue for assuring constant value delivery, is currently overlooked in research and represents a struggle for software companies. We have done a first step towards understanding the information needs of the main actors involved in the prioritization of ATD refactorings and feature development. We have investigated which prioritization aspects are most relevant in the prioritization activity: the results show that some important aspects, such as lead time, maintenance costs and risk, would largely benefit from the information related to the ATD effects, for which we present a mapping tool TABLE IV. We have also highlighted how measures of ATD effects, especially contagious debt, quality issues and “double” effort would be strongly appreciated by architects and POs developing software for 4 different large companies. The respondents would dedicate between 10 and 20% of the resources in order to manage ATD. Finally, we highlight the similarities and differences in evaluating different ATD effects and different prioritization aspects by POs and architects, for example their different concerns about big deliveries and maintenance costs. The next step, already in the authors’ plan, consists of conducting a version of this investigation involving a large sample of respondents from a large set of companies, in order to further strengthen the current case study-specific findings with a broad, quantitative investigation. Another important next step is to analyze the customer-related information used during the prioritization activity in order to understand how they are compared to the ATD effects in order to prioritize ATD refactoring against feature development.The ongoing research has primary focused on the definition of the dependency graph and the evaluation of the depend- ency predictor. The definition of the dependency graph was complemented with a statistical analysis of software versions and the evolution of SNA metrics (tackling RQ1). In this line, it was analysed how past decisions reflected in the software structure affect the future occurrence of dependencies, and smells thereof (tackling RQ3). In addition, it was analysed the descriptive power of both topological and content-based fea- tures for defining the similarity of components (tackling RQ2). The descriptive power of software-related metrics remains to be evaluated. Regarding smell prediction, evaluations focused on defining preliminary filtering strategies for cycles and hubs (tackling RQ4). At present, the research is oriented to perform a systematic study with more systems (and versions) to corroborate the initial findings reported in [9, 10]. Moreover, considering the errors in which learned models could incur, additional studies are being performed to introduce mechanisms of reinforcement learning to feed the predictions with new information obtained from the environment (or from the architect), as a means to establish the confidence of predictions and reducing the probability of false positives. Once the prediction technique is fully evaluated, it will be incorporated into a tool to evaluate the capabilities of the approach in a study with subjects in the context of real software projects. Finally, it is expected to include other types of architectural smells [15] in the work.In this paper, we argue that a focus on architecture and architecture-related technical debt can assist in optimizing releases for agility. As our analysis of the two development efforts on the DRNEP system demonstrates, a focus on the immediacy of the short-term value of features to be delivered must be widened before we can consider their consequences in ensuring long-term success. In the DRNEP case study, the two paths are normalized based on the priority of the features they deliver at each release, but the choice and the cost of the structural elements implementing the features diverge. At release 3 the need to pay back the technical debt resulting from the speedy delivery choices of the previous two releases is already apparent. Actively monitoring and making these decisions visible could have resulted in a re- architecting effort earlier that could still deliver a lower cost system for the value. The essence of our approach is thus: the value of the delivered features and the impact of cost to be incurred must be taken into account in decision-making related to delivering a product. Making the architectural debt visible provides the necessary information for making informed decisions for managing the potential impact of rework over time. Gaining visibility into system development requires a measurement-focused mindset at the system architecture level and the willingness to adjust courses of action during development. We demonstrated calculating rework cost based on the architecture rather than a focus on static code analysis. Calculating the rework cost is based on detecting the changing dependencies of the system that create an interest payment, which we accounted for with the change propagation metric. We used this rework cost in combination with calculating the value of the features delivered in the case study, to demonstrate how total ownership cost of system development can be effectively managed. We posit that rather than viewing technical debt as a reflection of low code quality in retrospect, it’s possible to leverage the notion of debt to manage system delivery. Deliberately borrowing time enables faster delivery and quicker value. The emerging system architecture must be visible to the development team to allow for calculating the accumulating potential rework cost as the system evolves. The architecture needs to be monitored over the course of development to support analysis on how debt is building up with interest and when to pay back the debt, also with consideration for how the cost and benefit trade off from the business perspective. Our experience has shown us that organizations have started building into their software development approaches active strategies about how debt will be elicited and kept active as needed. To date these approaches are mostly focused on exposing the fact that particular suboptimal decisions were made, in order to at least make sure that the decision is captured; however, payback and monitoring are still not common practice and techniques for both are lacking. It is this gap that our ongoing research aims to fill, contributing to improving the practice of software economics and software architecture practices with a quantifiable basis.The architecture problems identified by DV8 are one type of technical debt. DV8 provides two ways to quantify archi- tecture debt. First, DV8 detects Architecture Roots [15], which capture how bug-prone files are structurally connected and clustered together, and how they evolve over time. Considering each root as a debt [3], DV8 can calculate the maintenance costs of files involved in each root and the benefits achievable through refactoring. Second, DV8 detects architecture anti- patterns [6], that is, recurring architecture problems among files with significant impacts on bug-proneness and change- proneness. DV8 not only identifies these anti-patterns, but also quantifies the severity of each instance. DV8 has been repeatedly validated in industrial settings and greatly valued by practitioners [3], [8], [9], [11], [14]It was checked that the metrics coupling and cohesion can be used to identify ATD as modularity metrics. TD principal is able to predict the values of coupling and cohesion metrics at a statistically significant level, with however low accuracy. Nevertheless, it should be noted that TD is able to accurately (approx. 90%) predict the value of cohesion divided by cou- pling. This finding is particularity interesting in the sense that the TD assessment offered by SonarQube can be useful at both the implementation and the architecture design level. By comparing coupling and cohesion metrics that we used, one can observe that: (a) TD principal seems to be better related to cohesion, rather than coupling; and (b) TD principal is more closely related to TCIP rather than ACa. A main difference between the three metrics is that CaPC is a bounded metric (expressed as percentage), which therefore can be more easily interpreted. This finding is in accordance to previous studies suggested that bounded metrics are more strongly correlated with the existence of bad smells [9]. Regarding the two coupling metrics, the intensity of the dependencies seems to be more relevant to high level qualities, compared to a simple count of dependencies. This outcome is affirmed in previous studies (e.g., the MPC metric performs better than CBO) [5].In our research project we have started to investigate what ATD is relevant for the automotive domain. In this paper we have studied one kind of ATD: the deployment of software components violating the high-level architecture specification of the allowed dependencies. We have also investigated the im- pact (interest) of such sub-optimal solutions, which results in decreased efficiency of the communication within the vehicle. Such system quality is important for cars (and other embedded systems), since efficient communication and utilization of the networks within the car is crucial for the functionality of a car, but also for the long-term profitability as each increase in component cost is costly for a mass produced product. In this paper, we present a novel approach for visualizing the debt and the interest together. Such visualization helps the stakeholders identifying and prioritizing ATD, by under- standing the impact of different ATD items (specifically non- allowed dependencies) on efficiency. The validation interviews with the stakeholders at VCG confirmed that such tool would be valuable for architects and other stakeholders. Our approach analyzed architecture models on different levels to find the ATD items. This contributes to the existing body of knowledge, since most of the existing tools use source code as input, and we show how ATD can exist not only between implementation and architecture, but also between different levels of abstraction of the same architecture. In the future we plan to continue our research on what other ATD items can be found and what other impact measures can be combined together for having the complete picture of ATD and its interest, which would greatly help the decision making of the main stakeholders. We also plan to investigate the reasoning behind the architectural violations, whatever they are intentional or not, and whatever or which the architectural violations benefit the final product. Finally, stakeholders that were part of the early evaluation of the tool said that it would be valuable to see the evolution of the debt. They wanted to see if the tendency is that the debt increases or decreases over time, as well as see what impact planned or potential future changes would have. As seen on the title of the last tab in Fig. 6, the work of adding such functionality have started but, at the time of writing this paper, the functionality has not yet reached such status that it could be evaluated.In this paper, we described the different TDIs provided by five tools, and outlined their differences, with a particular focus on architecture-related issues. In the following, we provide answers to the questions posed in Sec. I. Q1 - In Sec. II, we described how the indexes are computed by the considered tools. They mainly take into account metrics, smells, coding rules violations and architecture violations, as shown in Tab. I. The estimations they provide are different in terms of unity of measure (e.g., time, cost, abstract numbers) and TD target (remediation costs and keeping costs), as shown in Tab. II. Q2 - Given the discussion on the indexes provided in Sec. III, we can see that: 1) Sonargraph, Structure101 and CAST use the largest share of architectural information in their indexes; 2) SonarQube does not use architectural information when computing its index. Q3 - First, we can observe that no tool uses all the information that can be exploited, at both code and architectural level, and no tool provides both Keeping and Resolution costs. Hence, tools could try to fill the gaps in their estimation models by re-using some knowledge exploited by other tools. Another observation is that tools are conservative in their estimation features, by relying only on static analysis and without exploiting historical information about the analyzed projects. In particular, most tools allow showing the history of their analyses on different revisions of the same project, but none of them uses the underlying changes in the software itself to spot issues relevant to Technical Debt estimation. In most cases, the available Indexes are not directly useful when evaluating a single project. The provided measures cannot be interpreted with the aim to understand the overall quality of the analyzed project on a global scale. As a consequence, we think that these Indexes are in particular useful on a relative scale, in the case a single team evaluates an entire portfolio of applications. In this case, the Index can be used, e.g., to rank new projects w.r.t. the old/existing ones. In future work, we are interested in verifying how much architectural issues affect the overall quality, with the aim of giving different relevance to architecture and design issues w.r.t. coding ones in a TDI. We plan to investigate the role of code and architectural smells in TD, since they are associated to known solutions, that can speed up their resolution process. We would like also to work on the definition of a new TDI, with a focus on code and architectural debt, and experiment it on a large dataset of projects. In the TDI computation we would like to consider: 1) Code and Architectural smells detection; 2) Code and architecture/design metrics; 3) History of a system, including code changes and lifespan of smells; 4) Identification of problems more critical than others, to weight the collected analysis elements (e.g., metrics, smells, issues) according to their relevance in existing (past) projectsOur work contributes to the emerging literature on technical debt, and in particular to studies which focus on those debts asso- ciated with system architecture. In particular, we show that mea- sures of coupling, which capture a file’s position within the net- work of system dependencies, are a strong predictor of subsequent file maintenance costs. We show this relationship is consistent across two software systems with very different designs; one has a “Hierarchical design”, the other has a “Core-periphery” design. Our work is distinctive and departs from prior work in that we use a measure of coupling that captures the direct and indirect depen- dencies each component has in a system, as well as the direction of these dependencies. These data can be used to classify the role of each file in the system, and hence to identify how changes may propagate through the system. The paper contributes to work that seeks to understand the po- tential value that can be released via architectural refactoring ef- forts that “pay down” architectural debt. Specifically, we combine financial data on the costs of maintaining components in different architectural categories, with empirical data on the outcomes of prior refactoring efforts, to project the value that could be released in each system. The results suggest greater value would come from refactoring the core-periphery system, which possesses a large core of almost 5000 mutually interdependent files. However, given the size and complexity of this system, the realization of this value would likely require a long-term commitment to modularize the system via frequent, small, incremental componentization efforts. Our methods provide guidance for which files one might target in such a process (i.e., Core files). And we provide anecdotal evidence from a senior developer in this system that this approach is prov- ing useful in paying down architectural debts.This study has investigated the evolution of instability architectural smells in the context of open source systems with respect to their characteristics and persistence. We presented multiple findings and practical implications useful both for practitioners and researchers that can help them improving the strategies for reducing long term maintenance efforts by managing architectural smells. As future work, we plan to extend our tooling to mine archi- tectural smells directly from Git repositories, thus allowing us to link the current information to code churn and investigate the effects of smells on change rates.In this paper we described the case study we performed in order to investigate the behaviour of the PageRank and the criticality of AS (RQ1). We detected through Arcan the AS in six projects, the criticality and the PageRank measures for each AS. We observed that often the two measures have the same trends, high criticality and high PageRank, but in some cases the trends are different, as we observed in particular for the Cyclic Dependency smell. Hence, both measures provide information useful for the developers to investigate the dangerous AS. We also analyzed the PageRank of a component affected by more than one AS (RQ2) and we observed that the PageRank of a component affected by more AS is higher. PageRank provides useful hints on the quality of a project, in order to identify the parts of the projects that need particular at- tention during maintenance and refactoring activities. PageRank identifies the smells with the highest impact on the project but these smells not necessarily represent the most critical ones. A developer interested in using the Arcan tool can detect the AS and give refactoring priority to the ones with high criticality and high PageRank, as we propose in this work. She can obtain different information from the two values, criticality and PageRank, and possibly combine them in order to identify very important com- ponents affected by highly critical AS, that need to be investigated and refactored. In this paper we outlined different refactoring sce- narios based on the values of the two metrics and in the future we plan to extend our study by leveraging historical data from version control systems of the analyzed projects. We aim also to extend the study by considering a large number of projects in different domains and also other AS as the tool support to detect them will be available. In this way we could use a correla- tion coefficient such as Pearson’s cor, Spearman’s rho or Kendall’s tau to assess whether there is any correlation between PageRank and criticality and check whether the correlation is statistically significant. Obviously, we have not analyzed the cost solving to remove the AS, but this study provides some hints that could be exploited also in this direction. Moreover, we would like to study how the refactoring of AS with high PageRank could generate higher maintenance costs. A study in this context has been done by MacCormack et al [16], where they analyze how components with different levels of coupling generate different maintenance costs. Another future investigation is toward a cross validation of the rank- ing of the architectural smells with the data on the bugs reported in the affected components considering also the historic information of the maintenance activities on the smelly components.We looked closely into the evolution of Unix from an ar- chitectural perspective by examining 30 core releases from the First Research Edition to FreeBSD 11. We triangulated data sources (source code, documentation, research papers and books, pioneers’ recollections) to extract valid and up- to-date data. We have procured and produced a wealth of data and made it available to the community [58], [74] for further studies. Our analysis yielded both qualitative and quantitative results. The qualitative examination allowed us to estab- lish a timeline with the most important milestones that shaped the Unix architecture; those milestones are detailed as components, connectors, patterns and principles as well as other key architecture decisions. We also discussed the rationale of those decisions and how they affected future de- velopments. Through the quantitative analysis we showed the trends on size growth for the seven principal feature types (user commands, system calls, libraries etc.), as well as complexity. We found a uniform growth in size but also some outliers, for which we conjectured correspond- ing explanations. We discovered that cyclomatic complexity grew at first, but was subsequently reduced especially for the library and the kernel, where code quality matters the most. Finally, we put the Unix evolution in context. First, by comparing the number of current FreeBSD features with that of five other current operating systems, we found a similar magnitude, indicative of their essential complexity. Second, by contrasting the cyclomatic complexity with the GNU coreutils, C library and the Linux kernel, we observed overall an inverted U-curve with some marked differences. Based on the results, we ventured on generalizing them by developing an initial theory on the architecture evolution of operating systems; the theory is comprised of 11 proposi- tions and their corresponding explanations. Numerous early design decisions survive the test of time and are still visible decades after their introduction. Nevertheless, innovation continues uninterruptedly to accommodate changes in com- puting technology and networking, although with a slower pace as decades go by. Furthermore, architectural technical debt creeps in mostly by retaining two or more functionally- equivalent facilities, but also by offering complicated under- used functionality that adds maintenance effort without much actual value. However, architectural technical debt does not reach critical levels, as its remediation is system- atic despite increasing size and complexity. Moreover, the philosophy of lightweight informal mechanisms instead of formal prescriptive ones, the drive for portability, and an intricate ecosystem of other operating systems and third parties are factors that shape the architectural evolution of large, long-lived operating systems. Nevertheless, given the current size and complexity of Unix, its evolution can only be sustained through the adoption of third-party sub- systems, while many large sub-systems have formed an architecture of their own. Looking forward, progress in hardware and applications will continue to exert evolutionary pressure on Unix’s ar- chitecture on several fronts. Flash storage and universal memory computing change how secondary storage is used and addressed; CPUs with tens of cores require support for finer-grained parallelism; GPU computing calls for appropriate high-level abstractions; deep learning methods change the nature of computation by elevating data into its main determinant; security and privacy demand fresh approaches both at the data center and at the edges; mobile and IoT devices impose demanding constraints on computing resources, power, and real-time performance. In addition, the operating system’s large code base and the backward compatibility requirements of existing applications hinder radical changes. In short, the Unix operating system architects have their work cut out.Although the Dagstuhl definition of TD limits contingencies to internal quality attributes, it is our position that security is a special case. When security weaknesses are identified in software, it is imperative that they are addressed expediently because although the maintenance associated with fixing a design flaw (i.e., TD principal) may not be cost prohibitive, the potential for damage to a business is. If a weakness is successfully exploited (as a vulnerability), then repairing the damage can be very costly. The TD interest associated with such a weakness can grow significantly at the moment an attacker is successful. The approach we have presented leverages an existing catalog and scoring mechanism to aid practitioners in prioritizing weaknesses as technical debt items hopefully informing the decision making process. We have successfully mapped a CWE hierarchy to an operationalization of Quamoco and have provided an example of using CWSS as a way to help prioritize TD items.This is the first study surveying the estimated magnitude of the interest paid on the accumulated TD in terms of perceived wasted time and effort. This study is based on a survey with 258 respondents and group interviews with 32 practitioners. The study has shown that software development practitioners estimate that 36 % of all development time is wasted due to TD and that Complex Architectural Design and Requirement TD generates the most negative impact on daily software development work. The most wasted time is spent on Understanding and/or Measuring TD. This study reveals that all roles are heavily affected by the interest of TD, but different roles are affected differently. The study also shows that the age of the software affects the amount of wasted time and the different activities where the time is spent on. These findings have significant implications; organizations need to be aware of how much time and resources they are spending on their interest of TD and to deliberately focus on the remediation of their TD.The technical debt metaphor can prove to be a suitable means for conveying the importance of maintainability to the developers of rapidly evolving software domains, such as the embedded systems. Before any targeted research activities are undertaken to support the management of TD, it is important to understand the perception of the TD concept among ES devel- opers. To this end, in this paper, we have performed a case study involving seven ES industries to investigate the most frequently occurring types of TD, the quality attributes usually associated with TD items, and the relation between the ex- pected lifetime of a component and the acknowledgement of the importance of maintainability. The findings indicate that the most recurring types of technical debt in embedded soft- ware industry are test, architectural, and code debt. At the same time, some quality attributes such as functionality, reliability, and performance are given higher priority compared to manag- ing technical debt. Finally, developers clearly acknowledge the need for low technical debt on components that are expected to have a longer lifetime, compared to more short-lived ones.According to 226 respondents in 15 software organizations, practitionersestimatetospend,onaverage,asubstantialamount of time trying to manage TD (25%). Software companies in Scandinavia are (or have become) more familiar with the TD metaphor with respect to previous studies, and a few of them have started tracking TD, even if only 7.2% of them apply a systematic process. This is due to the lack of knowledge of what is necessary to implement in terms of tools and processes, as well as a lack of awareness of what the negative effects of TD are before they occur. Moreover, we studied some approaches and found that an initial investment on preparing for the introduction of TD is necessary, which makes starting TD tracking less appealing. However, although there are some obstacles to overcome, some of the companies are proactively and strategically implementing a solution to make TD visible. To help this process, we propose a Strategic Adoption Model (SAMTTD), based both on the evidence collected across this study in combination with current literature. The Model can be used by practitioners to assess their Technical Debt tracking processandtoplanthenext steps. Besides, about 56.4% of intervieews no tracking TDM.This industrial case study was conducted to explore the challenges that requirements volatility poses to SW architecture design. Fifteen SW experts involved in SW architecture design in various business units were interviewed using a semi-structured interview as a guide. This study revealed factors causing requirements volatility as the well as the challenges posed by the requirement volatility in the case company, which provides SW solutions for companies and SW products for consumers in a global market. Through the study important challenges that requirements volatility poses to SW architecture design were identified. Finally, the means to address the identified challenges were discussed. Some factors, such as requirements uncertainty or missing information, the constant change of priorities and shifting and competing goals, are recognised as preventing architects from analysing available options and taking the optimal course of action in complex, real- world scenarios. As discussed, the context in which architecture is designed is very demanding, and architects prefer to compromise quality rather than increase overhead. However, there is a possibility that the same factors that are considered advantages also affect architecture design negatively. For example, even though light-weight documentation is considere an advantage, it can contribute to requirements volatility and increase the risk of creating architectural technical debt. As software engineering researchers are increasingly interested in the “twin peaks” of the software development: requirements and architecture design. This study provided empirical evidence about the relationship between them and how the process changes in one can affect another. The ultimate goal was to understand the complexity of the development environment and issues the practitioners face daily and thus propose feasible solutions for industry. This case study provides an example for practitioners how research may help to expose challenges, their reasons and impacts in the company. Practitioners may consult the results of the case study to identify similarities and differences in their practices. This in turn helps to find improvement directions. In future research, another case study will be conducted in a company of different size and in a different domain to investigate whether the same challenges are present there. Cross analysis between the case studies will provide new insights and help increasing the generalisability of the findings. Based on the results of those case studies, it is planned to develop a framework that provides means for practitioners to identify the presence of challenges posed by requirement volatility and take necessary steps to mitigate the risks.Decisions on short-term and long-term prioritization of archi- tecture refactoring need to be balanced and need to rely on the knowledge of the underlying phenomenon of ATD. The current management of ATD is an under-researched topic and we con- tribute to the empirical software engineering body of knowledge by reporting from a multiple case study investigating practitioners’ experiences from 7 large Scandinavian companies employing Agile and developing product lines of embedded software. In this paper we have shown what are the causes of the accumulation of ATD, and we outline, through the recognition of different influencing factors, clear objectives that can be treated or further studied in order to avoid or mitigate the accumulation of ATD (RQ1), therefore easing the ATD management for architects and managers. We have also presented 2 models for describing the accumulation and refactoring of ATD over time (RQ2). Such models are the Crisis Model and the Phases Model. Such models can be further stud- ied and tested with the conduction of experiments and the collec- tion of quantitative data by the ISERN community. Based on the models, we have identified possible strategies for refactoring ATD (RQ3) and we provided recommendations with respect to the minimization of development crises. We conclude that complete refactoring is not a possible strategy in the current studied companies, due to the continuous and inevitable accumu- lation of ATD and the impossibility of removing it all. The No refactoring strategy leads to crises points often, hindering the long-term responsiveness in providing new customer value, as required in ASD. The best strategy is therefore to apply partial refactoring to minimize crises and to push the crisis point as far as possible with respect to the lifecycle of the products. The results highlight differ- ent outcomes related to different ATD prioritization strategies, which would help architects and managers in balancing the ATD management strategies with respect to the business goals and the life-cycle of the products. An important goal in research and industry is to improve the practices and tools to uncover ATD present in the system and to keep track of it. It is also important to identify the best points in time for performing refactoring and therefore repaying the debt that is going to generate more interest effort later on. Such prac- tices need to complement the current Agile process in place, in order to keep responsiveness stable through the whole software development process.In this paper, we first proposed DRSpace, a new software architecture model that can be used to analyze implemented architecture in source code. DRSpace modeling captures multiple, overlapping design spaces in a complex system, so that distinct aspects of a system, such as a feature or a pattern, can be viewed and analyzed separately. As the first exploration of using DRSpace to reveal the architectural impact on software quality, we proposed the concept of ArchRoots—the DRSpaces that attract and prop- agate errors to multiple files, and their detection algorithm. Our research is unique in that it explicitly ties software quality—in terms of bug-proneness—to the modular struc- ture of software architecture and architecture flaws. From the 15 projects that we selected, with varying sizes, domains, and ages, we observed that 1) an bug-prone design rule can make a large number of files within it DRSpace also error-prone; 2) the impacts of architecture connections among bug-prone files are significant and persistent over time. In each project, a substantial percentage of bug-prone files, with different bug-proneness levels and in different time-spans, are constantly concentrated in the top five Arch- Roots. Our study also indicates that the impacts of archi- tecture connections among bug-prone files are persistent: there are long-lived architecture roots appearing in multiple releases of a project, connecting bug-prone files fixed in different time intervals. This suggests that, when fixing errors in a file, changes may propagate to other files that architecturally connect to it, and this impact can be persistent, lasting from months to years. The quantitative analysis of the architecture con- nections among bug-prone files shows that the architecture problems contained in the ArchRoots are likely to be the root causes of bug-proneness. The take-away message of our study is this: to increase the quality and reduce the number of bugs within a software system, practitioners should pay attention to high-impact bug-prone design rules, as well as the architecture roots aggregating bug-prone files. Our study also justified the value of further investigation of concrete architecture prob- lems: how they contribute to file bug-proneness, and their potential solutions, that is, the possible ways of refactoring.We conducted 17 interviews with software professionals from 10 companies and talked with them about the evolva- bility assurance for 14 different Microservice-based systems. We found that systems developed for an external customer in a project-like manner generally relied more on central governance for the assurance. Continuous product develop- ment of internal systems exhibited more decentralization and team autonomy for the assurance process. Guidelines like architectural principles or rules for service communication were seen as important to provide a consistent basis for evolvability and to frame an otherwise diverse technology usage. While participants saw automation and tool support as important for evolvability assurance, they still relied a lot on manual activities like code review or boy scouting. Tool and metric usage was very focused on source code quality. No architectural tools and metrics were applied, even though most reported challenges and issues like service cutting were related to software architecture. This may indicate the im- portance of Architectural Technical Debt (ATD) management for Microservices. Likewise, no tools or metrics specifically designed for service orientation were used, even though most participants stated the significance of their underlying design principles. Participants generally perceived their fairly new Microservices as decently evolvable, even though things like distributed code repositories and difficult macroarchitectural assessment would make the assurance process more complex. Future work that covers the areas of maintenance, evolution, and technical debt in the context of Microservices should take these findings and industry sentiments into account. In partic- ular, academia can support industry with methods, metrics, or tools that aid macroarchitectural assessment of Microservices or provide a more system-centric view. We perceived tool support for service cutting activities and metrics to evaluate service granularity, coupling, or cohesion as concrete gaps that could save industry a lot of refactoring efforts. Finally, issues in the area of human evolvability factors with Microservices like the handling of hyped technologies as well as coordinating and exchanging knowledge between decentralized teams were described as important by participants.Software code quality and technical debt have significant impact on a software product’s reliability and maintainability. This paper identifies a small, essential, set of static software code metrics linked to reliability and maintainability and to the most commonly identified sources of technical debt. A plug-in is created for the Understand code visualization and static analysis tool that calculates and aggregates the metrics and produces a high-level interactive html report as well as developer-level information needed to address quality issues. A script makes use of Git, Understand, and the plug-in to compile results for lists of GitHub repositories into a single file. While the plug-in is useful as-is, it was developed as a first step in an ongoing project aimed at applying case-based reasoning to the issue of software product quality. The next step in this project aims to use the described plug-in as part of a research effort to define and validate the aggregation of these metrics as part of a software quality model.business applications is formidable. For instance, even when applying the con- servative parameters in estimate 1, the average application is estimated to have $361,000 of TD-principal for each 100 KLOC. When the more realistic parameters of estimate 3 are applied, executives will likely dismiss the esti- mated size of TD-principal as exces- sive. However, when large estimates result from accurate parameters for an organization’s hours to fix and cost per hour, then the percent of violations to be fixed can be varied to determine how many violations can be remediated within existing budgets and which vio- lations to prioritize. We urge caution in interpreting the estimates we present in this article as industry benchmarks. This explo- ration of estimates for TD-principal demonstrates that these estimates are extremely sensitive both to the as- sumptions made in parameterizing the equation and the different types of languages to which they are applied. These estimates could also shift with changes in the mix of application char- acteristics in each language category as the number of applications grows in the Appmarq repository. Neverthe- less, these results provide a good start- ing point for exploring TD-principal, and one that can be adjusted based on different assumptions about the pa- rameters used. When developed with professional discipline, estimates of TD-principal can be a powerful tool to aid management in understanding and controlling IT costs and risks.Although TD-Principal can be measured as violations of good structural quality, these violations consist of different types of threats to the business or costs to IT. In order to use TD-Principal effectively in making decisions about how much resource to allocate to eliminating these violations, management needs to distinguish among its quality priorities and then prioritize the importance of eliminating TD- Principal in each area. Our data allow us to measure the TD- Principal associated with each of the five Health Factors since they represent different types of costs to IT or risks to the business. The amount of TD-Principal in an application associated with each of these Health Factors differs. Seventy percent of the TD-Principal measured in this sample was contained in the IT cost related Health Factors of Changeability (30%) and Transferability (40%). Thirty percent of the TD- Principal was associated with the business risk Health Factors of Robustness (18%), Security (7%), and Performance Efficiency (5%). We cannot determine from the data whether IT organizations are spending more time eliminating TD-Principal related to business risk or whether TD-Principal is disproportionately created in IT cost-related factors. Nevertheless, a single high severity violation related to business risk can be devastating if it eventually causes an operational problem.Since high-level principles such as abstraction, encapsulation, modularization, and hierarchy are quite generic, it is usually difficult to understand how to apply them in practice. To solve this problem, we can break down the fundamental principles to more granular “enabling techniques”, which helps us to understand the fundamental principles to a greater depth, but also ease the task of applying the principle in real-world situations. Increasingly complex and demanding business environment evolves with integration strategy and architecture. The security architecture design and technology stakeholders chosen should facilitate user to deliver a modular approach to integration that supports new security requirements such as micro-services-based security development. The key solution should include open standards and open source software, both in provisos of technology and permit the model to distribute the profit of open source while extenuating, mitigating the risks. In this work an attempt is made to identify various architectural design debts causing factors in a present day computing system with special reference to mul- tilateral security architectural design. To overcome the architectural design, debt refactoring is the existing solution to repay the debt which also helps in reducing the vulnerabilities in the present day computing system.In this paper, we have studied architectural technical debt specifically related to scalability, which we call scalability debt. We presented a case related to open systems (open banking), where uncertainty causes scalability debt to be acquired continuously. We argue that, in such systems, a continuous and lightweight approach to manage scalability debt is required. We report a lightweight method used in an open banking organization to identify, estimate and prioritize scalability debt. Such method consists of three phases, an initial triage to prioritize the areas with more likely impact due to scalability debt, a second phase where the debt is assessed in different affected subsystems and a third phase where the impact (interest) of the debt is calculated according to three scenarios. Different thresholds and colors were used to document and communicate the scalability debt and its impact to stakeholders. A feature of the approach is the way it involved experts in the organization, starting with a few core experts, attracting more attention and more experts and key roles as the analysis grows and the risks are being identified. The results can be taken into consideration by practitioners when dealing with scalability debt and may be used as starting point to develop the method presented here further or to research novel lightweight approaches to manage technical debt related to other key business qualities.In this paper, we investigated the possibility of using SATD comments to resolve architectural divergences. We leveraged a data set of classified SATD comments and traced them to bad architectural implementations that we surfaced by contrasting the conceptual and concrete architectures of ArgoUML, using its available design documentation and source code. Our study revealed 29 architectural divergences, 7 in high-level layers, and 22 among subsystems. Our preliminary results show that merely 4 out of 29 divergences (14%) can be directly traced to SATD, and that looking at SATD comments can provide enough information to fix them. To validate this, we manually implemented the changes as suggested by debt comments in each of the 4 traced divergences and confirmed that address- ing the comments directly leads to resolve the divergences. Although SATD can be used as an indicator for architectural divergences, it requires considerable time and effort, and will not result in a significant architectural improvement. To generalize our findings, we plan on replicating this study on a broader scale. Looking at SATD comments that can be traced to architectural divergences resulted effective in resolving them, thus, we plan to further investigate this with better architectural recovery and more advanced SATD detection approaches, potentially in an automated manner.Because there is little scientific research on the industry state of practice w.r.t. maintainability control in general and for SBSs and μSBSs specifically, we created a survey to find out about a) applied processes, tools, and metrics, b) satisfaction with this quality at- tribute, and c) potentially different treatment of systems based on service orientation. When analyzing the answers of 60 software professionals, we discovered that a combined 60% of our sample do not address maintainability at all or only implicitly at a very basic level. A combined 40% reported explicit handling, but only 10 participants reported using a systematic process. Furthermore, 40% of participants were not satisfied with the state of maintain- ability of their software. 35% were somewhat satisfied and only 25% reported to be pleased with the maintainability of their system. Lastly, ∼67% reported to not treat SBSs and μSBSs with special maintainability controls. ∼26% applied somewhat different controls and only ∼7% mentioned significantly different treatment. Since the sample population is limited in size however, further research in this area is necessary to confirm similar distribution in other parts of the population, probably also exclusively with companies that specialize in the development of SBSs and μSBSs. Regardless of the sample size though, some interesting points with potential impact for future research can be highlighted. First, there was extremely little reported usage of methods, tools, and met- rics that focused specifically on evolvability. While issues related to architecture-level evolvability were very present amongst the reported symptoms (e.g. architectural erosion or complexity or more time needed to add new functionality), very few participants reported actually addressing them. To avoid technical debt in a long-living software system, industry needs to improve their qual- ity control: they need to go beyond source code level metrics and also include an architecture-centric view on software evolution, potentially with scenario-based methods. A second take-away from this work is the suggested useful- ness of using a systematic process for maintainability control. While very few reported using such an approach, the vast major- ity of these 10 participants believed that this increased software quality and even wanted to invest more time for maintainability. People that used tools were also more likely to invest more time. To strengthen this, there was an overall correlation between the level of sophistication w.r.t. maintainability control and the reported sat- isfaction with this quality attribute: participants that used explicit and systematic approaches were more likely to be satisfied with the state of maintainability of their software. Moreover, no direct link between a hindrance in productivity and the level of sophistication of applied actions could be found. Lastly, the neglect of service-oriented particularities for quality control – especially on the metrics side – combined with the reported trust in the base level maintainability of service ori- entation could pose a threat for the quality of a long-living SBS. Aspects like service granularity, service cohesion, or service cou- pling can easily become problematic when not tended to and can significantly hinder the maintenance and evolution of such a system. Luckily, there was a correlation between treating service-oriented systems differently and the level of sophistication of applied ac- tions (on top of using tool support). So there is hope that with a rise in the general proficiency of maintainability control, under- standing for a different treatment of SBSs and μSBSs will grow as well. When looking specifically at the differences with treating Mi- croservices however, there is an even wider gap. Of the participants that reported different treatment, no one mentioned how poten- tial maintainability-related problems with increased technological heterogeneity, decentralization of control, or appropriate service granularity could be addressed. While these topics do not neces- sarily have to negatively impact maintainability, they still hold the potential to do so, if not executed with some care. Since this is a rather young topic, qualitative interviews with experts in the field of Microservices would most likely be a more effective approach.The main contribution of this paper is the introduction of the risk appetite concept into the architecture decision-making genre. This enabled the influence of the architects’ attitude towards risk on the architecture decision-making process to be classified and explored. Although the results seem to be sound and logical, it would be valuable to perform a broader industry survey to provide further insights into how architects approach risks, including how they assess the risks, what kind of reward they expect, and how they valuate these. This would validate the results of this paper to a greater extent, or possibly provide additional insights into the matter.This paper reports on patterns in the process of architecting and ways in which the connected debt can be measured and managed. The patterns in question were observed in an industrial case study and found that they result in what is called social debt, i.e., a picture of the current state of things burdened by suboptimal sociotechnical decisions. In the case of the patterns reported in this paper, a considerable part of architectural decisions or the very process of archi- tecting in a certain way had a negative and (previously) invisible sociotechnical connotation. This paper also reports on a practice observed in the case study to mitigate some of the nasty consequences connected to emerging social debt. Finally, the manuscript outlined DAHLIA, a sample metric for architectures to make (some) social debt explicit by measuring architectural (in)communicability, i.e., the likelihood that the developers’ network is (un)aware of architecture decisions. This paper contributions and discussions lead to the con- clusion that social debt and software architectures are tightly knit together and with technical debt as well and deserve further attention in the future. Further studies are planned to elaborate on the findings, expanding the understanding of the relations between social debt, its technical counterpart, and software architectures possibly with an immersive study in industry. Also, further studies are planned to understand the differences between social debt in closed-source industries (as reported in this paper) and open source, to possibly find successful architecting patterns elicited from open source, if any. In addition, several points highlighted in this paper remain open, for example: 1) what is the full mapping between software engineering economics concepts and the notion of social debt? 2) what is the role of interest repayment strategies as well as economic formulations around debt contraction and repayment as mapped to social debt? 3) what is the relation between effort-estimation techniques, the consequent organizational structure decisions, and the emergence of social debt? Finally, further studies are being planned to elaborate further on the proposed metric for software architecture communi- cability, demonstrating its representation condition [12] and applying it in industrial practice in the operational form, with the goal of providing more solid and quantitative validation for it.